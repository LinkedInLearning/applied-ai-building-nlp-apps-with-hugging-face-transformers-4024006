{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88015722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\kumar\\Anaconda3\\envs\\nlp-learn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "#Set to avoid warning messages.\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac3d23",
   "metadata": {},
   "source": [
    "## 03.02. Content Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4567c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing is a growing domain in machine learning applications. The purpose of this project is to provide a scalable way to develop a variety of languages on top of neural net technologies. Some applications are being developed that use the underlying neural network and can easily integrate with existing applications. These are shown below demonstrating \n",
      "-----------------\n",
      "Natural Language Processing is a growing domain in machine learning and there are numerous applications available in the field of AI in general. With the current state of AI research in AI, we are exploring these topics, including:\n",
      "\n",
      "Using AI for Machine Learning Science/Sustainability\n",
      "\n",
      "Using Machine Learning in \n",
      "-----------------\n",
      "Natural Language Processing is a growing domain in machine learning. This means that every new task, even one you've never thought to create, may be used as a foundation for generating a more comprehensive set of AI-based machine learning algorithms. But the problem of human error is getting the attention of other researchers \n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\", \n",
    "                          model=\"gpt2\")\n",
    "transformers.set_seed(1)\n",
    "\n",
    "input_text=\"Natural Language Processing is a growing domain in machine learning\"\n",
    "\n",
    "synthetic_text=text_generator(input_text,\n",
    "                              num_return_sequences=3,\n",
    "                              max_new_tokens=50)\n",
    "\n",
    "for text in synthetic_text:\n",
    "    print(text.get(\"generated_text\") ,\"\\n-----------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863bfa0e",
   "metadata": {},
   "source": [
    "## 03.04. Chatbot Conversation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b9b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline,AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name=\"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "conv_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "conv_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "conv_pipeline=pipeline(\"text-generation\",\n",
    "                       model=conv_model,\n",
    "                       tokenizer=conv_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943e7009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     User :  Do you have any hobbies?\n",
      "Assistant :  As an artificial intelligence, I don't have the capacity for physical activities or personal interests like humans do. However, I can assist with various tasks and provide information to help answer your questions. How may I assist you today?\n",
      "     User :  I like to watch movies\n",
      "Assistant :  That's great! Watching movies is a fantastic way to unwind and relax after a long day. What kind of movies would you recommend?\n",
      "     User :  action movies\n",
      "Assistant :  Action movies are definitely popular among audiences. Some highly recommended action films include \"Die Hard,\" \"The Terminator,\" \"Fast & Furious,\" \"Deadpool,\" and \"The Matrix.\" These films offer thrilling action sequences, memorable characters, and engaging storylines that keep viewers on the edge of their seats. Enjoy your movie-watching time!\n",
      "\n",
      "Accessing All Responses: \n",
      "{'role': 'system', 'content': 'You are a chatbot that engages in lively conversations'}\n",
      "{'role': 'user', 'content': 'Do you have any hobbies?'}\n",
      "{'role': 'assistant', 'content': \"As an artificial intelligence, I don't have the capacity for physical activities or personal interests like humans do. However, I can assist with various tasks and provide information to help answer your questions. How may I assist you today?\"}\n",
      "{'role': 'user', 'content': 'I like to watch movies'}\n",
      "{'role': 'assistant', 'content': \"That's great! Watching movies is a fantastic way to unwind and relax after a long day. What kind of movies would you recommend?\"}\n",
      "{'role': 'user', 'content': 'action movies'}\n",
      "{'role': 'assistant', 'content': 'Action movies are definitely popular among audiences. Some highly recommended action films include \"Die Hard,\" \"The Terminator,\" \"Fast & Furious,\" \"Deadpool,\" and \"The Matrix.\" These films offer thrilling action sequences, memorable characters, and engaging storylines that keep viewers on the edge of their seats. Enjoy your movie-watching time!'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create a list of chat input messages /responses\n",
    "chat_inputs = [\"Do you have any hobbies?\",\n",
    "        \"I like to watch movies\",\n",
    "        \"action movies\"]\n",
    "\n",
    "#Create the initial chat history\n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a chatbot that engages in lively conversations\"},\n",
    "]\n",
    "\n",
    "#Iterate over the input list and prompt the chat assistant\n",
    "for input in chat_inputs:\n",
    "  #Add input to the chat history\n",
    "  chat_history.append({\"role\": \"user\", \"content\": input})\n",
    "  #Generate output\n",
    "  chat_outputs = conv_pipeline(chat_history, max_new_tokens=512)\n",
    "\n",
    "  #Print the input and output\n",
    "  print(\"     User : \", chat_outputs[0][\"generated_text\"][-2]['content'])\n",
    "  print(\"Assistant : \", chat_outputs[0][\"generated_text\"][-1]['content'])\n",
    "\n",
    "  #Add output to chat history for future context.\n",
    "  chat_history.append(chat_outputs[0][\"generated_text\"][-1])\n",
    "\n",
    "print(\"\\nAccessing All Responses: \")\n",
    "for message in chat_outputs[0][\"generated_text\"] :\n",
    "  print(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf9be7f",
   "metadata": {},
   "source": [
    "## 03.06. Translating with Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0ea71b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Translation:  Acme ist ein Technologieunternehmen mit Sitz in New York und Paris.\n",
      "French Translation:  Acme est une société technologique basée à New York et à Paris.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "source_english=\"Acme is a technology company based in New York and Paris\"\n",
    "\n",
    "inputs_german = tokenizer(\n",
    "    \"translate English to German: \" + source_english,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "outputs_german = model.generate(\n",
    "    inputs_german[\"input_ids\"], \n",
    "    max_length=40)\n",
    "\n",
    "print(\"German Translation: \",\n",
    "      tokenizer.decode(outputs_german[0], \n",
    "                       skip_special_tokens=True))\n",
    "\n",
    "inputs_french = tokenizer(\n",
    "    \"translate English to French: \" + source_english, \n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "outputs_french = model.generate(\n",
    "    inputs_french[\"input_ids\"], \n",
    "    max_length=40)\n",
    "\n",
    "print(\"French Translation: \", \n",
    "      tokenizer.decode(outputs_french[0], \n",
    "                       skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
